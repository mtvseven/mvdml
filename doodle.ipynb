{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functioning-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# sklearn functions\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "mature-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Method for creating synthetic data for use in OLS problems.\n",
    "    \n",
    "    User specifies:\n",
    "       \n",
    "       N - number of observations\n",
    "       K - number of features\n",
    "    seed - a seed for np.random.seed()\n",
    "    '''\n",
    "    def synthOLS(self, N = 500, K = 10, seed = None):\n",
    "        \n",
    "        # set the randomization seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # define coefficients\n",
    "        b = (np.sin([1/K for K in range(1,(K + 1))]) + 0.01).reshape(-1, 1)\n",
    "        \n",
    "        # define the std deviates for the features\n",
    "        sigma = make_spd_matrix(K, 1)\n",
    "        \n",
    "        # create the feature matrices\n",
    "        X = np.random.multivariate_normal(np.ones(K), sigma, size = [N,])\n",
    "        \n",
    "        # define error terms\n",
    "        e = np.random.standard_normal(size=[N,]).reshape(-1, 1)\n",
    "        \n",
    "        # create the variables\n",
    "        y = X@b + e\n",
    "\n",
    "        return y, X\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Method for creating synthetic data for use in instrumental variables\n",
    "    problems.\n",
    "    \n",
    "    User specifies:\n",
    "        \n",
    "        N - number of observations\n",
    "        K - number of features\n",
    "     inst - number of instrumental variables\n",
    "    theta - the true effect of the treatment variable on the outcome\n",
    "     seed - a seed for np.random.seed()\n",
    "    '''\n",
    "    def synthIV(self, N = 500, K = 10, inst = 1, theta = 0.5, seed = None):\n",
    "        \n",
    "        # set the randomization seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # define coefficients\n",
    "        b1 = (\n",
    "            np.sin([1/K for K in range(1,(K + 1))]) + 0.01\n",
    "        ).reshape(-1, 1)\n",
    "        b2 = np.flip(b1)\n",
    "        bz = (\n",
    "            np.cos([1/inst for inst in range(1,(inst + 1))]) + 0.01\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "        # define the std deviates for the features\n",
    "        sigma1 = make_spd_matrix(K, 1)\n",
    "        sigma2 = make_spd_matrix(inst, 1)\n",
    "\n",
    "        # create the feature matrices\n",
    "        X = np.random.multivariate_normal(np.ones(K), sigma1, size = [N,])\n",
    "        z = np.random.multivariate_normal(np.ones(inst), sigma2, size = [N,])\n",
    "\n",
    "        # define error terms\n",
    "        e1 = np.random.standard_normal(size=[N,]).reshape(-1, 1)\n",
    "        e2 = np.random.standard_normal(size=[N,]).reshape(-1, 1)\n",
    "\n",
    "        # create the variables\n",
    "        d = z@bz + X@b1 + e1\n",
    "        y = np.dot(theta,d) + X@b2 + e2\n",
    "\n",
    "        return y, d, z, X\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Method for creating synthetic data for use in double machine\n",
    "    learning (DML) problems. It is important to note that there are\n",
    "    IV methods for DML and this function does not create data for those.\n",
    "    This function makes synthetic data for the OLS equivalent of the\n",
    "    problem.\n",
    "    \n",
    "    User specifies:\n",
    "        \n",
    "        N - number of observations\n",
    "        K - number of features\n",
    "    theta - the true effect of the treatment variable on the outcome\n",
    "     seed - a seed for np.random.seed()\n",
    "    '''\n",
    "    def synthDML(self, N = 500, K = 10, theta = 0.5, seed = None):\n",
    "    \n",
    "        # set the randomization seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # define \n",
    "        b = np.sin([1/K for K in range(1,(K + 1))]) + 0.01\n",
    "        sigma = make_spd_matrix(K, 1)\n",
    "        X = np.random.multivariate_normal(np.ones(K), sigma, size = [N,])\n",
    "\n",
    "        # if no functions are supplied for \n",
    "        def g(x):\n",
    "            return np.power(np.sin(x),2)\n",
    "        def m(x,nu=0.,gamma=1.):\n",
    "            return 0.5/np.pi*(np.sinh(gamma))/(np.cosh(gamma)-np.cos(x-nu))\n",
    "\n",
    "        # define error terms\n",
    "        e1 = np.random.standard_normal(size=[N,])\n",
    "        e2 = np.random.standard_normal(size=[N,])\n",
    "\n",
    "        # compute the variables\n",
    "        G = g(np.dot(X,b))\n",
    "        M = m(np.dot(X,b))\n",
    "        d = M + e1\n",
    "        y = np.dot(theta,d) + G + e2\n",
    "\n",
    "        return y, d, X\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Method for taking a list of numbers and returning n *mostly* equal\n",
    "    partitions of randomly shuffeled elements of the list. Primary purpose\n",
    "    is to act as a helper function for the dml method.\n",
    "    \n",
    "    User specifies:\n",
    "    \n",
    "    list_in - the list to be shuffeled and partitioned\n",
    "          n - the number of partitions to split the list into\n",
    "    '''\n",
    "    # function to create splits for cross-fitting\n",
    "    def partition (self, list_in, n):\n",
    "        random.shuffle(list_in)\n",
    "        return [list_in[i::n] for i in range(n)]\n",
    "\n",
    "    # function to use splits for orthogonalization\n",
    "    def orthog(self, ind, dep, indices, mod):\n",
    "\n",
    "        # fit the model\n",
    "        modfit = mod.fit(\n",
    "            np.delete(ind, indices, 0),\n",
    "            np.delete(dep, indices, 0).ravel()\n",
    "        )\n",
    "\n",
    "        # predict\n",
    "        dephat = modfit.predict(\n",
    "            ind[indices]\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "        # residualize\n",
    "        depres = dep[indices] - dephat\n",
    "\n",
    "        return depres\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Method for implementing the double machine learning (DML) algorithm\n",
    "    as specified in Chernozhukov et al., 2016. Users interested in the\n",
    "    detailed workings of the algorithm should consult that paper or\n",
    "    Chernozhukov's github (https://github.com/VC2015/DMLonGitHub) where\n",
    "    similar code and examples may be found.\n",
    "    \n",
    "    User specifies:\n",
    "    \n",
    "         X - a numpy array of exogenous covariates\n",
    "         y - a numpy array of a single outcome variable\n",
    "         d - a numpy array of a single treatment variable\n",
    "      ymod - a scikit-learn ML model to residualize the outcome\n",
    "      dmod - a scikit-learn ML model to residualize the treatment\n",
    "    splits - number of splits to produce for cross fitting\n",
    "    '''\n",
    "    def dml(self, y, d, X, ymod, dmod = None, splits = 2):\n",
    "\n",
    "        # reshape the data if necessary\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        if len(d.shape) == 1:\n",
    "            d = d.reshape(-1, 1)\n",
    "\n",
    "        # double model logic\n",
    "        if dmod is None:\n",
    "            dmod = ymod\n",
    "\n",
    "        # split indices\n",
    "        I = self.partition(list(range(len(y))), splits)\n",
    "\n",
    "        # initialize empty lists\n",
    "        dlist  = np.empty((0,1), float)\n",
    "        ylist  = np.empty((0,1), float)\n",
    "        thetas = np.empty((0,1), float)\n",
    "\n",
    "        # perform cross-fitting\n",
    "        for i in I:\n",
    "\n",
    "            # get orthogonalized treatment\n",
    "            dorth = self.orthog(X, d, i, dmod)\n",
    "            dlist = np.append(dlist, dorth, 0)\n",
    "\n",
    "            # get orthogonalized response\n",
    "            yorth = self.orthog(X, y, i, ymod)\n",
    "            ylist = np.append(ylist, yorth, 0)\n",
    "\n",
    "            # calculate intermediate thetas\n",
    "            thetas = np.append(thetas,\n",
    "                               np.mean(dorth*yorth)/np.mean(dorth**2))\n",
    "\n",
    "        # prep post-orthogonalization regressors\n",
    "        D = np.hstack( (np.ones((len(dlist), 1)) , dlist) )\n",
    "\n",
    "        # fit the DML2 model\n",
    "        coefs = np.linalg.lstsq(D, ylist, rcond = None)[0]\n",
    "\n",
    "        # get var-cov matrix for DML2\n",
    "        res = ylist - (coefs[0]*D[0] + coefs[1]*D[1])\n",
    "        vcv = np.true_divide(1, len(y) - 2\n",
    "        )*np.dot(np.dot(res.T,res), np.linalg.inv(np.dot(D.T, D)))\n",
    "\n",
    "        # get DML1 and DML2 coefficient\n",
    "        theta1 = np.mean(thetas)\n",
    "        theta2 = coefs[1]\n",
    "\n",
    "        # calculate the dml1 standard error\n",
    "        se1 = np.sqrt(np.mean( (ylist - theta1*dlist)**2*dlist**2\n",
    "                ) / (np.mean(dlist**2)**2)\n",
    "            ) / np.sqrt(len(dlist) - 1)\n",
    "\n",
    "        # calculate the dml2 standard error\n",
    "        se2 = np.sqrt(np.diagonal(vcv))[1]\n",
    "\n",
    "        # present the output\n",
    "        return {\n",
    "            'dml1':{\n",
    "                'coef_se':np.hstack((theta1, se1))\n",
    "            },\n",
    "            'dml2':{\n",
    "                'coef_se':np.hstack((theta2, se2))\n",
    "            },\n",
    "            'orth_data':np.hstack((ylist, dlist)),\n",
    "            'indices':I\n",
    "        }\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Method for implementing the instrumental variables double machine\n",
    "    learning (DML) algorithm as specified in Chernozhukov et al., 2016.\n",
    "    Users interested in the detailed workings of the algorithm should\n",
    "    consult that paper or Chernozhukov's github\n",
    "    (https://github.com/VC2015/DMLonGitHub) where similar code and\n",
    "    examples may be found.\n",
    "    \n",
    "    User specifies:\n",
    "    \n",
    "         X - a numpy array of exogenous covariates\n",
    "         y - a numpy array of a single outcome variable\n",
    "         d - a numpy array of a single treatment variable\n",
    "         z - a numpy array of instrumental variables\n",
    "      ymod - a scikit-learn ML model to residualize the outcome\n",
    "      dmod - a scikit-learn ML model to residualize the treatment\n",
    "    splits - number of splits to produce for cross fitting\n",
    "    '''\n",
    "    def dmlIV(self, y, d, z, X, ymod, dmod = None, zmod = None, splits = 2):\n",
    "\n",
    "        # reshape the data if necessary\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        if len(d.shape) == 1:\n",
    "            d = d.reshape(-1, 1)\n",
    "        if len(z.shape) == 1:\n",
    "            z = z.reshape(-1, 1)\n",
    "\n",
    "        # double model logic\n",
    "        if dmod is None:\n",
    "            dmod = ymod\n",
    "        if zmod is None:\n",
    "            zmod = ymod\n",
    "\n",
    "        # split indices\n",
    "        I = self.partition(list(range(len(y))), splits)\n",
    "\n",
    "        # initialize empty lists\n",
    "        zlist  = np.empty((0,1), float)\n",
    "        dlist  = np.empty((0,1), float)\n",
    "        ylist  = np.empty((0,1), float)\n",
    "\n",
    "        # perform cross-fitting\n",
    "        for i in I:\n",
    "\n",
    "            # get orthogonalized instrument\n",
    "            zorth = self.orthog(X, z, i, zmod)\n",
    "            zlist = np.append(zlist, zorth, 0)\n",
    "\n",
    "            # get orthogonalized treatment\n",
    "            dorth = self.orthog(X, d, i, dmod)\n",
    "            dlist = np.append(dlist, dorth, 0)\n",
    "\n",
    "            # get orthogonalized response\n",
    "            yorth = self.orthog(X, y, i, ymod)\n",
    "            ylist = np.append(ylist, yorth, 0)\n",
    "\n",
    "        return tsls(ylist, dlist, zlist)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def tsls(self, y, d, z, X = None, robust_se = False):\n",
    "        \n",
    "        # reshape arrays if necessary\n",
    "        if X is not None:\n",
    "            if len(X.shape) == 1:\n",
    "                X = X.reshape(-1, 1)\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        if len(d.shape) == 1:\n",
    "            d = d.reshape(-1, 1)\n",
    "        if len(z.shape) == 1:\n",
    "            z = z.reshape(-1, 1)\n",
    "\n",
    "        # define obs-column parameters\n",
    "        n = d.shape[0]\n",
    "\n",
    "        if X is not None:\n",
    "            k = X.shape[1] + d.shape[1]\n",
    "        else:\n",
    "            k = d.shape[1]\n",
    "\n",
    "        # restack arrays for matrix multiplication\n",
    "        if X is not None:\n",
    "            X = np.hstack((d, X))\n",
    "            Z = np.hstack((z, X))\n",
    "        else:\n",
    "            X = d\n",
    "            Z = z\n",
    "\n",
    "        # 2SLS weighting matrix and X projection\n",
    "        P = Z@np.linalg.inv(Z.T@Z)@Z.T\n",
    "        X_h = P@X\n",
    "\n",
    "        # get (X'PX)^(-1) in var-covar formula\n",
    "        X_inv = np.linalg.inv(X_h.T@X_h)\n",
    "\n",
    "        # 2SLS estimation\n",
    "        b = X_inv@X_h.T@y\n",
    "\n",
    "        # calculate error variance\n",
    "        e = y - np.dot(X_h, b)\n",
    "        SSE = e.T@e\n",
    "        var_e = SSE/(n - k)\n",
    "\n",
    "        # get either robust or standard middle term\n",
    "        if robust_se:\n",
    "            omega = np.diag(np.diag(e@e.T))\n",
    "        else:\n",
    "            omega = var_e*np.identity(n)\n",
    "\n",
    "        # calculate var-covar matrix\n",
    "        vcv = X_inv@X_h.T@omega@X_h@X_inv\n",
    "\n",
    "        # get se by sqroot of diag\n",
    "        se = np.sqrt(np.diagonal(vcv))\n",
    "\n",
    "        return np.hstack((b, se.reshape(-1, 1)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def ols(self, y, X, robust_se = False):\n",
    "\n",
    "        # reshape arrays if necessary\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        n = X.shape[0]\n",
    "        k = X.shape[1]\n",
    "\n",
    "        # get (X'X)^(-1) in var-covar and coeff formula\n",
    "        X_inv = np.linalg.inv(X.T@X)\n",
    "\n",
    "        # coef estimation\n",
    "        b = X_inv@X.T@y\n",
    "\n",
    "        # calculate the error variance\n",
    "        e = y - np.dot(X, b)\n",
    "        SSE = e.T@e\n",
    "        var_e = SSE/(n - k)\n",
    "\n",
    "        # get either robust or standard middle term\n",
    "        if robust_se:\n",
    "            omega = (n/(n - k))*np.diag(np.diag(e@e.T))\n",
    "        else:\n",
    "            omega = var_e*np.identity(n)\n",
    "\n",
    "        # calculate the var-covar matrix\n",
    "        vcv = X_inv@X.T@omega@X@X_inv\n",
    "\n",
    "        # get se by sqroot of diag\n",
    "        se = np.sqrt(np.diagonal(vcv))\n",
    "\n",
    "        return np.hstack((b, se.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "configured-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = make_regression(n_samples = 1000, n_features = 10, n_targets = 1)\n",
    "y, d, z, X = Metrics().synthIV(N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "smart-nepal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51041291, 0.01546852]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metrics().dmlIV(y, d, z, X, ymod = ElasticNetCV(), splits = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "previous-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50758  , 0.0154988]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsls(y, d, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "organized-bosnia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50758   , 0.01546897]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsls(y, d, z, robust_se = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
